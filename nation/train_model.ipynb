{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhcDxmXw6iuX"
      },
      "source": [
        "### Установка файлов и импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "djZoZcXywh5L"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "import chromadb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
        "    f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2inC-le6nh6"
      },
      "source": [
        "### Функции для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q47r-aHHwo56"
      },
      "outputs": [],
      "source": [
        "class EmbeddingsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for loading embeddings\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            source_path,\n",
        "            split,\n",
        "            source_type,\n",
        "            collection_name=\"nationality_embeddings\"):\n",
        "        self.lb = LabelEncoder()\n",
        "\n",
        "        if source_type == \"npy\":\n",
        "            self.embeddings, self.labels = self.get_npy_embeddings(\n",
        "                source_path, split)\n",
        "        elif source_type == \"chromadb\":\n",
        "            self.embeddings, self.labels = self.get_chroma_embeddings(\n",
        "                source_path, split, collection_name)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Invalid source type: {source_type}. \"\n",
        "                \"Choose 'npy' or 'chromadb'.\"\n",
        "            )\n",
        "\n",
        "        self.embeddings = torch.tensor(self.embeddings, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
        "\n",
        "    def get_npy_embeddings(self, source_path, split):\n",
        "        \"\"\"\n",
        "        Reads embddings from a .npy file\n",
        "        \"\"\"\n",
        "        source = np.load(os.path.join(\n",
        "            source_path, \"numpy_embs.npy\"), allow_pickle=True)\n",
        "        source = source[0]\n",
        "\n",
        "        if split == \"train\":\n",
        "            embeddings = np.array([item['embedding']\n",
        "                                  for item in source['train']])\n",
        "            labels = [item['label'] for item in source['train']]\n",
        "        elif split == \"test\":\n",
        "            embeddings = np.array([item['embedding']\n",
        "                                  for item in source['test']])\n",
        "            labels = [item['label'] for item in source['test']]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Invalid split. Expected 'test' or 'train', got {split}\")\n",
        "        labels = self.lb.fit_transform(labels)\n",
        "        return embeddings, labels\n",
        "\n",
        "    def get_chroma_embeddings(\n",
        "            self,\n",
        "            source_path,\n",
        "            split,\n",
        "            collection_name=\"nationality_embeddings\"):\n",
        "        \"\"\"\n",
        "        Reads embeddings from ChromaDB\n",
        "        \"\"\"\n",
        "        client = chromadb.PersistentClient(path=source_path)\n",
        "        collection = client.get_collection(name=collection_name)\n",
        "        results = collection.get(where={\"split\": split}, include=[\n",
        "            \"embeddings\", \"metadatas\"])\n",
        "        embeddings = np.array(results['embeddings'], dtype=np.float32)\n",
        "        labels = [item['label'] for item in results['metadatas']]\n",
        "\n",
        "        labels = self.lb.fit_transform(labels)\n",
        "        return embeddings, labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kixT9c3HyV3I"
      },
      "outputs": [],
      "source": [
        "def get_loaders(source_path, source_type):\n",
        "    \"\"\"\n",
        "    Creates dataloaders for train and test files\n",
        "    \"\"\"\n",
        "    train_dataset = EmbeddingsDataset(\n",
        "        source_path, split=\"train\", source_type=source_type)\n",
        "    test_dataset = EmbeddingsDataset(\n",
        "        source_path, split=\"test\", source_type=source_type)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return (\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        test_dataset,\n",
        "        train_dataset.embeddings.shape[1]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YkeAKmzHzHOD"
      },
      "outputs": [],
      "source": [
        "class NationalityCls(nn.Module):\n",
        "    \"\"\"\n",
        "    Baseline model class for nationality classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=256, num_classes=16):\n",
        "        super(NationalityCls, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.activation(self.fc1(x))\n",
        "        output = self.fc2(self.dropout(x1))\n",
        "        return x1, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UBqhnWp-0VHr"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, criterion, num_epoch, device):\n",
        "    \"\"\"\n",
        "    Train a model on a train dataset\n",
        "    \"\"\"\n",
        "    for epoch in tqdm(range(num_epoch), desc=\"Training Progress\"):\n",
        "        model.train()\n",
        "\n",
        "        for embeddings_batch, labels_batch in train_loader:\n",
        "            embeddings_batch = embeddings_batch.to(device)\n",
        "\n",
        "            labels_batch = labels_batch.long()\n",
        "            _, outputs = model(embeddings_batch)\n",
        "            # print(outputs.shape, labels_batch.shape)\n",
        "            loss = criterion(outputs, labels_batch.to(device))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qBbo-RZt0wLu"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluates a model on a test dataset. Calculates accuracy,\n",
        "    precision, recall and f1-score\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_samples_test = 0\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():\n",
        "        for embeddings_batch, labels_batch in tqdm(\n",
        "                test_loader, desc=\"Evaluation Progress\"):\n",
        "            embeddings_batch = embeddings_batch.to(device)\n",
        "\n",
        "            labels_batch = labels_batch.long()\n",
        "            x1, outputs = model(embeddings_batch)\n",
        "\n",
        "            total_samples_test += 1\n",
        "\n",
        "            _, predicted = torch.max(outputs.cpu(), 1)\n",
        "            true_labels.extend(labels_batch.numpy())\n",
        "            pred_labels.extend(predicted.numpy())\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(true_labels, pred_labels),\n",
        "        \"precision\": precision_score(true_labels, pred_labels,\n",
        "                                     average=\"weighted\"),\n",
        "        \"recall\": recall_score(true_labels, pred_labels,\n",
        "                               average=\"weighted\"),\n",
        "        \"f1_score\": f1_score(true_labels, pred_labels,\n",
        "                             average=\"weighted\")\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HbGkdJGx3q8U"
      },
      "outputs": [],
      "source": [
        "def save_metrics(metrics, save_path):\n",
        "    \"\"\"\n",
        "    Saves computed metrics in .txt file\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        for key, value in metrics.items():\n",
        "            f.write(f\"{key}: {value}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HHjNs53N3v96"
      },
      "outputs": [],
      "source": [
        "def save_visualization(model, vectors, labels, save_path, device):\n",
        "    \"\"\"\n",
        "    Saves embedding visualization in .png files\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    vectors = torch.FloatTensor(vectors).to(device)\n",
        "    with torch.no_grad():\n",
        "        x1, predicted = model(vectors)\n",
        "\n",
        "    reducer = TSNE(n_components=2, random_state=42)\n",
        "    x1_reduced = reducer.fit_transform(x1.detach().cpu().numpy())\n",
        "\n",
        "    unique_labels = list(set(labels))\n",
        "    encoded_labels = list(test_dataset.lb.classes_)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for label in unique_labels[:8]:\n",
        "        indices = [i for i, lbl in enumerate(labels) if lbl == label]\n",
        "        plt.scatter(\n",
        "            x1_reduced[indices, 0],\n",
        "            x1_reduced[indices, 1],\n",
        "            label=f\"Label: {encoded_labels[label]}\",\n",
        "            alpha=0.6\n",
        "        )\n",
        "\n",
        "    plt.title(\"Visualization of embeddings after first layer\")\n",
        "    plt.legend()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltt7tRbv6rVJ"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8WvPgvov4ih1"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WuzW55vP4mJ8"
      },
      "outputs": [],
      "source": [
        "train_loader, test_loader, test_dataset, input_dim = get_loaders(\n",
        "    r'C:\\Users\\Nastya\\Desktop\\interp_dev-main\\Chroma', 'chromadb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1JpZcZ3Y44fL"
      },
      "outputs": [],
      "source": [
        "model = NationalityCls(input_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuuZXkAH5G1Q",
        "outputId": "cd43264d-753c-4d95-9b05-a09cd7fbab20"
      },
      "outputs": [],
      "source": [
        "train(model, train_loader, optimizer, criterion, num_epoch=100, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vuXiehA5_N1",
        "outputId": "b8b68ec3-5fa8-4719-8a6e-2074f99c5bc3"
      },
      "outputs": [],
      "source": [
        "metrics = evaluate(model, test_loader, device)\n",
        "save_metrics(metrics, r\"C:\\Users\\Nastya\\Desktop\\interp_dev-main\\age\\results\\Nationality.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "lZLa-XwiCPoP"
      },
      "outputs": [],
      "source": [
        "save_visualization(\n",
        "    model, test_dataset.embeddings.numpy(),\n",
        "    test_dataset.labels.numpy(), r'C:\\Users\\Nastya\\Desktop\\interp_dev-main\\age\\results\\NationalityCls.png', device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JkH6LcnKGgeq"
      },
      "outputs": [],
      "source": [
        "torch.save(model, r\"C:\\Users\\Nastya\\Desktop\\interp_dev-main\\nationality\\nation\\results\\ya_loh.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
