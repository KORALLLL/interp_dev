{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!gdown 1rlVuOy_S-iQRmiXJbWlofORPbA-WtZhn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0tsOhtJKSUO",
        "outputId": "c7502cbe-aa26-4012-b64e-15f327377172"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rlVuOy_S-iQRmiXJbWlofORPbA-WtZhn\n",
            "To: /content/chromadb.zip\n",
            "\r  0% 0.00/3.73M [00:00<?, ?B/s]\r 70% 2.62M/3.73M [00:00<00:00, 18.2MB/s]\r100% 3.73M/3.73M [00:00<00:00, 25.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/chromadb.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('embeddings')"
      ],
      "metadata": {
        "id": "lM9s_CuVAvLX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "jBbtI8IpxK1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QaC6cGNvw8iG"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import chromadb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
        "    f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for loading embeddings\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            source_path,\n",
        "            split,\n",
        "            source_type,\n",
        "            collection_name=\"gender_embeddings\"):\n",
        "        self.lb = LabelEncoder()\n",
        "\n",
        "        if source_type == \"npy\":\n",
        "            self.embeddings, self.labels = self.get_npy_embeddings(\n",
        "                source_path, split)\n",
        "        elif source_type == \"chromadb\":\n",
        "            self.embeddings, self.labels = self.get_chroma_embeddings(\n",
        "                source_path, split, collection_name)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Invalid source type: {source_type}. \"\n",
        "                \"Choose 'npy' or 'chromadb'.\"\n",
        "            )\n",
        "\n",
        "        self.embeddings = torch.tensor(self.embeddings, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
        "\n",
        "    def get_npy_embeddings(self, source_path, split):\n",
        "        \"\"\"\n",
        "        Reads embddings from a .npy file\n",
        "        \"\"\"\n",
        "        source = np.load(os.path.join(\n",
        "            source_path, \"numpy_embs.npy\"), allow_pickle=True)\n",
        "        source = source[0]\n",
        "\n",
        "        if split == \"train\":\n",
        "            embeddings = np.array([item['embedding']\n",
        "                                  for item in source['train']])\n",
        "            labels = [item['label'] for item in source['train']]\n",
        "        elif split == \"test\":\n",
        "            embeddings = np.array([item['embedding']\n",
        "                                  for item in source['test']])\n",
        "            labels = [item['label'] for item in source['test']]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Invalid split. Expected 'test' or 'train', got {split}\")\n",
        "        labels = self.lb.fit_transform(labels)\n",
        "        return embeddings, labels\n",
        "\n",
        "    def get_chroma_embeddings(\n",
        "            self,\n",
        "            source_path,\n",
        "            split,\n",
        "            collection_name=\"gender_embeddings\"):\n",
        "        \"\"\"\n",
        "        Reads embeddings from ChromaDB\n",
        "        \"\"\"\n",
        "        client = chromadb.PersistentClient(path=source_path)\n",
        "        collection = client.get_collection(name=collection_name)\n",
        "        results = collection.get(where={\"split\": split}, include=[\n",
        "            \"embeddings\", \"metadatas\"])\n",
        "        embeddings = np.array(results['embeddings'], dtype=np.float32)\n",
        "        labels = [item['label'] for item in results['metadatas']]\n",
        "\n",
        "        labels = self.lb.fit_transform(labels)\n",
        "        return embeddings, labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.labels[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)"
      ],
      "metadata": {
        "id": "Ubkl1anqxsDs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DisorderCls(nn.Module):\n",
        "    \"\"\"\n",
        "    Baseline model class for gender classification\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=256, num_classes=3):\n",
        "        super(DisorderCls, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.fc1(x)\n",
        "        x1 = self.relu(x1)\n",
        "        x2 = self.fc2(x1)\n",
        "        return x1, x2"
      ],
      "metadata": {
        "id": "gvnnURYjx0Ca"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, num_epoch, device):\n",
        "    \"\"\"\n",
        "    Train a model on a train dataset\n",
        "    \"\"\"\n",
        "    for epoch in tqdm(range(num_epoch), desc=\"Training Progress\"):\n",
        "        model.train()\n",
        "\n",
        "        for embeddings_batch, labels_batch in train_loader:\n",
        "            embeddings_batch = embeddings_batch.to(device)\n",
        "\n",
        "            labels_batch = labels_batch.long()\n",
        "            _, outputs = model(embeddings_batch)\n",
        "            loss = criterion(outputs, labels_batch.to(device))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "id": "HKpUwhlJykks"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluates a model on a test dataset. Calculates accuracy,\n",
        "    precision, recall and f1-score\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_samples_test = 0\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():\n",
        "        for embeddings_batch, labels_batch in tqdm(\n",
        "                test_loader, desc=\"Evaluation Progress\"):\n",
        "            embeddings_batch = embeddings_batch.to(device)\n",
        "\n",
        "            labels_batch = labels_batch.long()\n",
        "            x1, outputs = model(embeddings_batch)\n",
        "\n",
        "            total_samples_test += 1\n",
        "\n",
        "            _, predicted = torch.max(outputs.cpu(), 1)\n",
        "            true_labels.extend(labels_batch.numpy())\n",
        "            pred_labels.extend(predicted.numpy())\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(true_labels, pred_labels),\n",
        "        \"precision\": precision_score(true_labels, pred_labels, average=\"weighted\"),\n",
        "        \"recall\": recall_score(true_labels, pred_labels, average=\"weighted\"),\n",
        "        \"f1_score\": f1_score(true_labels, pred_labels, average=\"weighted\")\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "x2sFk-wfyuQ1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loaders(source_path, source_type):\n",
        "    \"\"\"\n",
        "    Creates dataloaders for train and test files\n",
        "    \"\"\"\n",
        "    train_dataset = EmbeddingsDataset(\n",
        "        source_path, split=\"train\", source_type=source_type)\n",
        "    test_dataset = EmbeddingsDataset(\n",
        "        source_path, split=\"test\", source_type=source_type)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return (\n",
        "        train_loader,\n",
        "        test_loader,\n",
        "        test_dataset,\n",
        "        train_dataset.embeddings.shape[1]\n",
        "    )"
      ],
      "metadata": {
        "id": "sQBpDgQtyu-D"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_visualization(model, vectors, labels, save_path, device):\n",
        "    \"\"\"\n",
        "    Saves embedding visualization in .png files\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    vectors = torch.FloatTensor(vectors).to(device)\n",
        "    with torch.no_grad():\n",
        "        x1, predicted = model(vectors)\n",
        "\n",
        "    reducer = TSNE(n_components=2, random_state=42)\n",
        "    x1_reduced = reducer.fit_transform(x1.detach().cpu().numpy())\n",
        "\n",
        "    unique_labels = list(set(labels))\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for label in unique_labels:\n",
        "        indices = [i for i, lbl in enumerate(labels) if lbl == label]\n",
        "        plt.scatter(\n",
        "            x1_reduced[indices, 0],\n",
        "            x1_reduced[indices, 1],\n",
        "            label=f\"Label: {label}\",\n",
        "            alpha=0.6\n",
        "        )\n",
        "\n",
        "    plt.title(\"Visualization of embeddings after first layer\")\n",
        "    plt.legend()\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "2UJLybaWy9pb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_metrics(metrics, save_path):\n",
        "    \"\"\"\n",
        "    Saves computed metrics in .txt file\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        for key, value in metrics.items():\n",
        "            f.write(f\"{key}: {value}\\n\")"
      ],
      "metadata": {
        "id": "3eoWQvJfy_it"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_loader, test_loader, test_dataset, input_dim = get_loaders(\n",
        "    '/content/embeddings/chromadb', 'chromadb'\n",
        ")\n",
        "model = DisorderCls(input_dim).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "train(model, train_loader, optimizer,\n",
        "      criterion, num_epoch=200, device=device)\n",
        "\n",
        "metrics = evaluate(model, test_loader, device)\n",
        "save_metrics(metrics, '/content/result/SpeechDisorder.txt')\n",
        "save_visualization(\n",
        "    model, test_dataset.embeddings.numpy(),\n",
        "    test_dataset.labels.numpy(), '/content/result/SpeechDisorder.png', device=device\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VUnvj8UzDQy",
        "outputId": "de9872c8-1d52-43e3-ee36-35911052c818"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 200/200 [00:20<00:00,  9.79it/s]\n",
            "Evaluation Progress: 100%|██████████| 12/12 [00:00<00:00, 862.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, \"/content/weights.pth\")"
      ],
      "metadata": {
        "id": "m31T2W8P22UB"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}