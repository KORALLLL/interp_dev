CCA Similarity: Model Activations vs Phoneme Duration
============================================================

Duration: short
----------------------------------------
first relu: 0.000643
layer1 relu: 0.000475
SimAM: 0.000328
layer1 relu: 0.000328
layer1 relu: 0.000506
SimAM: 0.000473
layer1 relu: 0.000473
layer1 relu: 0.000517
SimAM: 0.000358
layer1 relu: 0.000358
layer2 relu: 0.000845
SimAM: 0.000322
layer2 relu: 0.000322
layer2 relu: 0.000637
SimAM: 0.000440
layer2 relu: 0.000440
layer2 relu: 0.000613
SimAM: 0.000589
layer2 relu: 0.000589
layer2 relu: 0.000816
SimAM: 0.000640
layer2 relu: 0.000640
layer3 relu: 0.001714
SimAM: 0.000728
layer3 relu: 0.000728
layer3 relu: 0.000929
SimAM: 0.000726
layer3 relu: 0.000726
layer3 relu: 0.000937
SimAM: 0.001003
layer3 relu: 0.001003
layer3 relu: 0.001127
SimAM: 0.001239
layer3 relu: 0.001239
layer3 relu: 0.001386
SimAM: 0.001465
layer3 relu: 0.001465
layer3 relu: 0.001830
SimAM: 0.001446
layer3 relu: 0.001446
layer4 relu: 0.002872
SimAM: 0.001736
layer4 relu: 0.001736
layer4 relu: 0.001269
SimAM: 0.001676
layer4 relu: 0.001676
layer4 relu: 0.002124
SimAM: 0.001433
layer4 relu: 0.001433
pooling: 0.006624

Duration: medium
----------------------------------------
first relu: 0.000434
layer1 relu: 0.000611
SimAM: 0.000339
layer1 relu: 0.000339
layer1 relu: 0.000513
SimAM: 0.000354
layer1 relu: 0.000354
layer1 relu: 0.000431
SimAM: 0.000310
layer1 relu: 0.000310
layer2 relu: 0.000416
SimAM: 0.000268
layer2 relu: 0.000268
layer2 relu: 0.000684
SimAM: 0.000159
layer2 relu: 0.000159
layer2 relu: 0.000313
SimAM: 0.000333
layer2 relu: 0.000333
layer2 relu: 0.000713
SimAM: 0.000317
layer2 relu: 0.000317
layer3 relu: 0.000549
SimAM: 0.000919
layer3 relu: 0.000919
layer3 relu: 0.000478
SimAM: 0.000776
layer3 relu: 0.000776
layer3 relu: 0.000176
SimAM: 0.000472
layer3 relu: 0.000472
layer3 relu: 0.000445
SimAM: 0.000397
layer3 relu: 0.000397
layer3 relu: 0.001076
SimAM: 0.000554
layer3 relu: 0.000554
layer3 relu: 0.000264
SimAM: 0.001037
layer3 relu: 0.001037
layer4 relu: 0.002608
SimAM: 0.001617
layer4 relu: 0.001617
layer4 relu: 0.001300
SimAM: 0.000524
layer4 relu: 0.000524
layer4 relu: 0.001399
SimAM: 0.000948
layer4 relu: 0.000948
pooling: 0.008786

