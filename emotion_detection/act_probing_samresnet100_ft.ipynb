{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gojT4sn_E7UF",
        "outputId": "fb18a3e6-aac9-4786-a7c0-6f228ffca042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/wenet-e2e/wespeaker.git\n",
            "  Cloning https://github.com/wenet-e2e/wespeaker.git to /tmp/pip-req-build-9yaah54d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/wenet-e2e/wespeaker.git /tmp/pip-req-build-9yaah54d\n",
            "  Resolved https://github.com/wenet-e2e/wespeaker.git to commit 310a15850895b54e20845e107b54c9a275d39a2d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from wespeaker==0.0.0) (4.67.1)\n",
            "Requirement already satisfied: kaldiio in /usr/local/lib/python3.11/dist-packages (from wespeaker==0.0.0) (2.18.1)\n",
            "Requirement already satisfied: hdbscan==0.8.37 in /usr/local/lib/python3.11/dist-packages (from wespeaker==0.0.0) (0.8.37)\n",
            "Requirement already satisfied: umap-learn==0.5.6 in /usr/local/lib/python3.11/dist-packages (from wespeaker==0.0.0) (0.5.6)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from wespeaker==0.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from wespeaker==0.0.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: silero-vad in /usr/local/lib/python3.11/dist-packages (from wespeaker==0.0.0) (5.1.2)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.37->wespeaker==0.0.0) (0.29.37)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.37->wespeaker==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.37->wespeaker==0.0.0) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.37->wespeaker==0.0.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan==0.8.37->wespeaker==0.0.0) (1.5.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn==0.5.6->wespeaker==0.0.0) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn==0.5.6->wespeaker==0.0.0) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->wespeaker==0.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->wespeaker==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.16.1 in /usr/local/lib/python3.11/dist-packages (from silero-vad->wespeaker==0.0.0) (1.22.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn==0.5.6->wespeaker==0.0.0) (0.43.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->silero-vad->wespeaker==0.0.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->silero-vad->wespeaker==0.0.0) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->silero-vad->wespeaker==0.0.0) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.16.1->silero-vad->wespeaker==0.0.0) (5.29.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20->hdbscan==0.8.37->wespeaker==0.0.0) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->wespeaker==0.0.0) (3.0.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.16.1->silero-vad->wespeaker==0.0.0) (10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/wenet-e2e/wespeaker.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import torchaudio.compliance.kaldi as kaldi\n",
        "from tqdm import tqdm\n",
        "import wespeaker"
      ],
      "metadata": {
        "id": "BGLD6QspFC0M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationDataset(Dataset):\n",
        "    def __init__(self, activation_paths, labels):\n",
        "        self.activation_paths = activation_paths\n",
        "        self.y = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        activation = np.load(self.activation_paths[idx])\n",
        "        act_tensor = torch.from_numpy(activation).float()\n",
        "        act_tensor = act_tensor.view(-1)\n",
        "        return act_tensor, self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ],
      "metadata": {
        "id": "43OVW68aFCyC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetActivations(nn.Module):\n",
        "    \"\"\"\n",
        "    Class for getting activations from a model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        super(GetActivations, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.permute(0, 2, 1)\n",
        "        activations = []\n",
        "        model_front = self.model.model.front\n",
        "\n",
        "        x = out.unsqueeze(dim=1)\n",
        "\n",
        "        out = model_front.relu(model_front.bn1(model_front.conv1(x)))\n",
        "\n",
        "        activations.append({\"first relu\": out})\n",
        "\n",
        "        for name, layer in model_front.named_children():\n",
        "            c_sim = 0\n",
        "            c_relu = 0\n",
        "            if name in ['layer1', 'layer2', 'layer3', 'layer4']:\n",
        "                for sec_name, sec_layer in layer.named_children():\n",
        "                    identity = out\n",
        "\n",
        "                    out = sec_layer.relu(sec_layer.bn1(sec_layer.conv1(out)))\n",
        "                    c_relu += 1\n",
        "                    activations.append({f\"{name} relu {c_relu}\": out})\n",
        "\n",
        "                    out = sec_layer.bn2(sec_layer.conv2(out))\n",
        "                    out = sec_layer.SimAM(out)\n",
        "                    c_sim += 1\n",
        "                    activations.append({f\"{name} SimAM {c_sim}\": out})\n",
        "\n",
        "                    if sec_layer.downsample is not None:\n",
        "                        identity = sec_layer.downsample(identity)\n",
        "\n",
        "                    out += identity\n",
        "                    out = sec_layer.relu(out)\n",
        "                    c_relu += 1\n",
        "                    activations.append({f\"{name} relu {c_relu}\": out})\n",
        "\n",
        "        out = self.model.model.pooling(out)\n",
        "        activations.append({\"pooling\": out})\n",
        "\n",
        "        if self.model.model.drop:\n",
        "            out = self.model.model.drop(out)\n",
        "\n",
        "        out = self.model.model.bottleneck(out)\n",
        "\n",
        "        return activations, out"
      ],
      "metadata": {
        "id": "iCyLaANPFCwE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionCls(nn.Module):\n",
        "    def __init__(self, input_dim=256, num_classes=5):\n",
        "        super(EmotionCls, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.relu(self.fc1(x))\n",
        "        x2 = self.fc2(x1)\n",
        "        return x2"
      ],
      "metadata": {
        "id": "Ckq3wTx_FCtr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_fbank(wavform,\n",
        "                  sample_rate=16000,\n",
        "                  num_mel_bins=80,\n",
        "                  frame_length=25,\n",
        "                  frame_shift=10,\n",
        "                  cmn=True):\n",
        "    feat = kaldi.fbank(wavform,\n",
        "                       num_mel_bins=num_mel_bins,\n",
        "                       frame_length=frame_length,\n",
        "                       frame_shift=frame_shift,\n",
        "                       sample_frequency=sample_rate)\n",
        "    if cmn:\n",
        "        feat = feat - torch.mean(feat, 0)\n",
        "    return feat"
      ],
      "metadata": {
        "id": "Svp_npjOFCrq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resample_rate = 16000\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def extract_feature_from_pcm(pcm: torch.Tensor, sample_rate: int):\n",
        "    pcm = pcm.to(torch.float)\n",
        "    if sample_rate != resample_rate:\n",
        "        pcm = torchaudio.transforms.Resample(\n",
        "            orig_freq=sample_rate, new_freq=resample_rate)(pcm)\n",
        "    feats = compute_fbank(pcm,\n",
        "                          sample_rate=resample_rate,\n",
        "                          cmn=True)\n",
        "    feats = feats.unsqueeze(0)\n",
        "    feats = feats.to(device)\n",
        "\n",
        "    return feats"
      ],
      "metadata": {
        "id": "JSZddgo2FCpN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(wavform: torch.Tensor, sample_rate: int):\n",
        "    return extract_feature_from_pcm(wavform, sample_rate)"
      ],
      "metadata": {
        "id": "YJRwEDc6FCnd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_audio_path(audio_dir):\n",
        "    \"\"\"\n",
        "    Recursively finds all audio files in the specified directory.\n",
        "    \"\"\"\n",
        "    audio_dir = Path(audio_dir)\n",
        "    audio_files = list(audio_dir.glob('**/*.wav'))\n",
        "    return audio_files"
      ],
      "metadata": {
        "id": "Dd7qKPemFClL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_activations(model, audio_path, device,\n",
        "                    target_samples=16000):\n",
        "    \"\"\"\n",
        "    Gets model activations.\n",
        "    \"\"\"\n",
        "    wavform, samples = torchaudio.load(audio_path)\n",
        "\n",
        "    if wavform.shape[1] < target_samples:\n",
        "        pad = (0, target_samples - wavform.shape[1])\n",
        "        wavform = torch.nn.functional.pad(wavform, pad)\n",
        "    else:\n",
        "        wavform = wavform[:, :target_samples]\n",
        "\n",
        "    feats = extract_features(wavform, samples)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        activations = model(feats)\n",
        "\n",
        "    acts = {\n",
        "        \"file_path\": str(audio_path),\n",
        "        \"act\": activations[0] if isinstance(activations, tuple) else activations\n",
        "    }\n",
        "    return acts"
      ],
      "metadata": {
        "id": "ekU85EatFCjB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_activations_for_layer(model, audio_files, device, layer_name,\n",
        "                              target_samples=16000):\n",
        "    \"\"\"\n",
        "    Gets model activations for a specified layer.\n",
        "    \"\"\"\n",
        "    label_map = {}\n",
        "    path_to_dataset_split = Path(audio_files[0]).parent.parent\n",
        "    split = path_to_dataset_split.name\n",
        "    metadata_path = path_to_dataset_split / f\"{split}_metadata.jsonl\"\n",
        "\n",
        "    with open(metadata_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            entry = json.loads(line)\n",
        "            audio_path = entry[\"audio_path\"].replace(\"\\\\\", os.sep)\n",
        "            file_name = os.path.basename(audio_path)\n",
        "            emotion = entry[\"speaker_emo\"]\n",
        "            label_map[file_name] = emotion\n",
        "\n",
        "    labels = []\n",
        "    for f in audio_files:\n",
        "        file_name = Path(f).name\n",
        "        labels.append(label_map[file_name])\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "    save_dir = Path(\"activations\") / layer_name\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    activation_paths = []\n",
        "    filtered_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for audio_path in tqdm(audio_files,\n",
        "            desc=f\"Extracting {layer_name} activations\"\n",
        "        ):\n",
        "            wavform, samples = torchaudio.load(str(audio_path))\n",
        "            if wavform.shape[1] < target_samples:\n",
        "                pad = (0, target_samples - wavform.shape[1])\n",
        "                wavform = torch.nn.functional.pad(wavform, pad)\n",
        "            else:\n",
        "                wavform = wavform[:, :target_samples]\n",
        "\n",
        "            feats = extract_features(wavform, samples).to(device)\n",
        "            acts, _ = model(feats)\n",
        "\n",
        "            activation = next((d[layer_name]\n",
        "                              for d in acts if layer_name in d), None)\n",
        "            if activation is not None:\n",
        "                file_name = Path(audio_path).name\n",
        "                label = label_map[file_name]\n",
        "\n",
        "                file_path = save_dir / f\"{Path(audio_path).stem}.npy\"\n",
        "                np.save(file_path, activation.cpu().numpy())\n",
        "\n",
        "                activation_paths.append(file_path)\n",
        "                filtered_labels.append(label_encoder.transform([label])[0])\n",
        "    return activation_paths, filtered_labels"
      ],
      "metadata": {
        "id": "V8X6oUtgFChB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, input_size, layer, device, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Train a model on a train dataset\n",
        "    \"\"\"\n",
        "    model = EmotionCls(input_size).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training Progress\"):\n",
        "        model.train()\n",
        "\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xE8rZkrDFCZm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluates a model on a test dataset.\n",
        "    Calculates accuracy and f1-score\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(\n",
        "                test_loader, desc=\"Evaluation Progress\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            outputs = model(X)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f1_score\": f1_score(y_true, y_pred, average=\"macro\")\n",
        "    }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "x48gk_AxFV5T"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(metrics_list, save_path):\n",
        "    layers = [m[0] for m in metrics_list]\n",
        "    accuracies = [m[1][\"accuracy\"] for m in metrics_list]\n",
        "    f1_scores = [m[1][\"f1_score\"] for m in metrics_list]\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, len(layers)+1), accuracies, color='b', label=\"Accuracy\")\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy across layers\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, len(layers)+1), f1_scores, color='g', label=\"F1-score\")\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"F1-score\")\n",
        "    plt.title(\"F1-score across layers\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path)"
      ],
      "metadata": {
        "id": "y9nHBVrcFVyS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_metrics(metrics_list, save_path):\n",
        "    \"\"\"\n",
        "    Saves computed metrics in .txt file\n",
        "    \"\"\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        for layer, metrics in metrics_list:\n",
        "            f.write(f\"{layer}\\n\")\n",
        "            for key, value in metrics.items():\n",
        "                f.write(f\"{key}: {value}\\n\")"
      ],
      "metadata": {
        "id": "lZ-H2dnlFVtf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = wespeaker.load_model_local(\"/content/drive/MyDrive/Project_practicum/pretrain_dir\")\n",
        "model.set_device(device)\n",
        "\n",
        "acts_model = GetActivations(model)"
      ],
      "metadata": {
        "id": "YxC-nwNwFVnP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = get_audio_path(\"/content/drive/MyDrive/Project_practicum/dataset/train\")\n",
        "test_files = get_audio_path(\"/content/drive/MyDrive/Project_practicum/dataset/test\")"
      ],
      "metadata": {
        "id": "XNuuHzohFdyU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acts = get_activations(acts_model, train_files[0], device)\n",
        "layers = [list(item.keys())[0] for item in acts[\"act\"]]"
      ],
      "metadata": {
        "id": "AHgtz_dAFduD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_list = []\n",
        "\n",
        "for layer in layers:\n",
        "    train_acts, train_labels = get_activations_for_layer(\n",
        "        acts_model, train_files, device, layer)\n",
        "    test_acts, test_labels = get_activations_for_layer(\n",
        "        acts_model, test_files, device, layer)\n",
        "\n",
        "    train_dataset = ActivationDataset(train_acts, train_labels)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "    test_dataset = ActivationDataset(test_acts, test_labels)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    input_size = train_dataset[0][0].shape[0]\n",
        "\n",
        "    trained_model = train(train_loader, input_size,\n",
        "                          layer, device)\n",
        "\n",
        "    model_path = os.path.join(\"/content/drive/MyDrive/Project_practicum/models\",\n",
        "                              f\"{layer}.pth\")\n",
        "    torch.save(trained_model.state_dict(), model_path)\n",
        "\n",
        "    metrics = evaluate(trained_model, test_loader, device)\n",
        "    metrics_list.append((layer, metrics))\n",
        "\n",
        "    layer_activation_dir = Path(\"activations\") / layer\n",
        "    if layer_activation_dir.exists():\n",
        "        shutil.rmtree(layer_activation_dir)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "save_metrics(metrics_list, \"/content/drive/MyDrive/Project_practicum/results/voxblink2_samresnet100_ft/probing.txt\")\n",
        "plot_metrics(metrics_list, \"/content/drive/MyDrive/Project_practicum/results/voxblink2_samresnet100_ft/probing.png\")"
      ],
      "metadata": {
        "id": "2N57lnV5FhS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3689e93e-03a8-499b-fd44-593683434a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting first relu activations: 100%|██████████| 1588/1588 [01:37<00:00, 16.29it/s]\n",
            "Extracting first relu activations: 100%|██████████| 1123/1123 [01:00<00:00, 18.65it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:48<00:00,  4.89s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:11<00:00,  6.13it/s]\n",
            "Extracting layer1 relu 1 activations: 100%|██████████| 1588/1588 [01:23<00:00, 19.05it/s]\n",
            "Extracting layer1 relu 1 activations: 100%|██████████| 1123/1123 [00:59<00:00, 18.74it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:45<00:00,  4.56s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:12<00:00,  5.62it/s]\n",
            "Extracting layer1 SimAM 1 activations: 100%|██████████| 1588/1588 [01:23<00:00, 18.99it/s]\n",
            "Extracting layer1 SimAM 1 activations: 100%|██████████| 1123/1123 [00:58<00:00, 19.22it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:43<00:00,  4.33s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:12<00:00,  5.84it/s]\n",
            "Extracting layer1 relu 2 activations: 100%|██████████| 1588/1588 [01:22<00:00, 19.22it/s]\n",
            "Extracting layer1 relu 2 activations: 100%|██████████| 1123/1123 [00:57<00:00, 19.51it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:42<00:00,  4.29s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:11<00:00,  6.33it/s]\n",
            "Extracting layer1 relu 3 activations: 100%|██████████| 1588/1588 [01:27<00:00, 18.17it/s]\n",
            "Extracting layer1 relu 3 activations: 100%|██████████| 1123/1123 [00:58<00:00, 19.28it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:46<00:00,  4.64s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:10<00:00,  6.53it/s]\n",
            "Extracting layer1 SimAM 2 activations: 100%|██████████| 1588/1588 [01:25<00:00, 18.59it/s]\n",
            "Extracting layer1 SimAM 2 activations: 100%|██████████| 1123/1123 [00:58<00:00, 19.07it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:46<00:00,  4.68s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:10<00:00,  7.09it/s]\n",
            "Extracting layer1 relu 4 activations: 100%|██████████| 1588/1588 [01:25<00:00, 18.52it/s]\n",
            "Extracting layer1 relu 4 activations: 100%|██████████| 1123/1123 [00:57<00:00, 19.64it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:45<00:00,  4.57s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:08<00:00,  8.31it/s]\n",
            "Extracting layer1 relu 5 activations: 100%|██████████| 1588/1588 [01:27<00:00, 18.15it/s]\n",
            "Extracting layer1 relu 5 activations: 100%|██████████| 1123/1123 [00:57<00:00, 19.60it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:45<00:00,  4.53s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:10<00:00,  6.57it/s]\n",
            "Extracting layer1 SimAM 3 activations: 100%|██████████| 1588/1588 [01:23<00:00, 18.97it/s]\n",
            "Extracting layer1 SimAM 3 activations: 100%|██████████| 1123/1123 [00:58<00:00, 19.05it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:44<00:00,  4.48s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:12<00:00,  5.87it/s]\n",
            "Extracting layer1 relu 6 activations: 100%|██████████| 1588/1588 [01:26<00:00, 18.35it/s]\n",
            "Extracting layer1 relu 6 activations: 100%|██████████| 1123/1123 [00:57<00:00, 19.50it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:45<00:00,  4.54s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:12<00:00,  5.70it/s]\n",
            "Extracting layer1 relu 7 activations: 100%|██████████| 1588/1588 [01:26<00:00, 18.44it/s]\n",
            "Extracting layer1 relu 7 activations: 100%|██████████| 1123/1123 [01:00<00:00, 18.62it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:42<00:00,  4.25s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:09<00:00,  7.14it/s]\n",
            "Extracting layer1 SimAM 4 activations: 100%|██████████| 1588/1588 [01:22<00:00, 19.27it/s]\n",
            "Extracting layer1 SimAM 4 activations: 100%|██████████| 1123/1123 [00:58<00:00, 19.22it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:45<00:00,  4.51s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:12<00:00,  5.56it/s]\n",
            "Extracting layer1 relu 8 activations: 100%|██████████| 1588/1588 [01:27<00:00, 18.18it/s]\n",
            "Extracting layer1 relu 8 activations: 100%|██████████| 1123/1123 [00:57<00:00, 19.63it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:43<00:00,  4.34s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:10<00:00,  6.96it/s]\n",
            "Extracting layer1 relu 9 activations: 100%|██████████| 1588/1588 [01:23<00:00, 18.94it/s]\n",
            "Extracting layer1 relu 9 activations: 100%|██████████| 1123/1123 [01:01<00:00, 18.36it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:43<00:00,  4.34s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:12<00:00,  5.77it/s]\n",
            "Extracting layer1 SimAM 5 activations: 100%|██████████| 1588/1588 [01:25<00:00, 18.55it/s]\n",
            "Extracting layer1 SimAM 5 activations: 100%|██████████| 1123/1123 [00:57<00:00, 19.46it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:47<00:00,  4.71s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:10<00:00,  6.82it/s]\n",
            "Extracting layer1 relu 10 activations: 100%|██████████| 1588/1588 [01:25<00:00, 18.49it/s]\n",
            "Extracting layer1 relu 10 activations: 100%|██████████| 1123/1123 [00:56<00:00, 20.02it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:45<00:00,  4.56s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:11<00:00,  6.23it/s]\n",
            "Extracting layer1 relu 11 activations: 100%|██████████| 1588/1588 [01:21<00:00, 19.45it/s]\n",
            "Extracting layer1 relu 11 activations: 100%|██████████| 1123/1123 [00:56<00:00, 19.93it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:48<00:00,  4.84s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:11<00:00,  5.95it/s]\n",
            "Extracting layer1 SimAM 6 activations: 100%|██████████| 1588/1588 [01:23<00:00, 19.05it/s]\n",
            "Extracting layer1 SimAM 6 activations: 100%|██████████| 1123/1123 [00:56<00:00, 19.77it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:44<00:00,  4.49s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:10<00:00,  6.51it/s]\n",
            "Extracting layer1 relu 12 activations: 100%|██████████| 1588/1588 [01:22<00:00, 19.34it/s]\n",
            "Extracting layer1 relu 12 activations: 100%|██████████| 1123/1123 [00:57<00:00, 19.68it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:44<00:00,  4.44s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:10<00:00,  6.48it/s]\n",
            "Extracting layer2 relu 1 activations: 100%|██████████| 1588/1588 [01:20<00:00, 19.72it/s]\n",
            "Extracting layer2 relu 1 activations: 100%|██████████| 1123/1123 [00:54<00:00, 20.50it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 59.84it/s]\n",
            "Extracting layer2 SimAM 1 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.68it/s]\n",
            "Extracting layer2 SimAM 1 activations: 100%|██████████| 1123/1123 [00:54<00:00, 20.56it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 57.80it/s]\n",
            "Extracting layer2 relu 2 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.76it/s]\n",
            "Extracting layer2 relu 2 activations: 100%|██████████| 1123/1123 [00:54<00:00, 20.65it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 66.98it/s]\n",
            "Extracting layer2 relu 3 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.67it/s]\n",
            "Extracting layer2 relu 3 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.28it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:16<00:00,  1.63s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 68.87it/s]\n",
            "Extracting layer2 SimAM 2 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.19it/s]\n",
            "Extracting layer2 SimAM 2 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.33it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.88it/s]\n",
            "Extracting layer2 relu 4 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.01it/s]\n",
            "Extracting layer2 relu 4 activations: 100%|██████████| 1123/1123 [00:53<00:00, 20.90it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 53.94it/s]\n",
            "Extracting layer2 relu 5 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.05it/s]\n",
            "Extracting layer2 relu 5 activations: 100%|██████████| 1123/1123 [00:54<00:00, 20.61it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.07it/s]\n",
            "Extracting layer2 SimAM 3 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.66it/s]\n",
            "Extracting layer2 SimAM 3 activations: 100%|██████████| 1123/1123 [00:53<00:00, 21.01it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.12it/s]\n",
            "Extracting layer2 relu 6 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.13it/s]\n",
            "Extracting layer2 relu 6 activations: 100%|██████████| 1123/1123 [00:53<00:00, 21.00it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 66.29it/s]\n",
            "Extracting layer2 relu 7 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.07it/s]\n",
            "Extracting layer2 relu 7 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.21it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 58.62it/s]\n",
            "Extracting layer2 SimAM 4 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.28it/s]\n",
            "Extracting layer2 SimAM 4 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.42it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 58.76it/s]\n",
            "Extracting layer2 relu 8 activations: 100%|██████████| 1588/1588 [01:17<00:00, 20.40it/s]\n",
            "Extracting layer2 relu 8 activations: 100%|██████████| 1123/1123 [00:53<00:00, 20.92it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.57s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 66.77it/s]\n",
            "Extracting layer2 relu 9 activations: 100%|██████████| 1588/1588 [01:15<00:00, 20.91it/s]\n",
            "Extracting layer2 relu 9 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.25it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.59s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 63.34it/s]\n",
            "Extracting layer2 SimAM 5 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.84it/s]\n",
            "Extracting layer2 SimAM 5 activations: 100%|██████████| 1123/1123 [00:53<00:00, 20.84it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 57.06it/s]\n",
            "Extracting layer2 relu 10 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.14it/s]\n",
            "Extracting layer2 relu 10 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.49it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.57s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 64.59it/s]\n",
            "Extracting layer2 relu 11 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.03it/s]\n",
            "Extracting layer2 relu 11 activations: 100%|██████████| 1123/1123 [00:54<00:00, 20.68it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.07it/s]\n",
            "Extracting layer2 SimAM 6 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.82it/s]\n",
            "Extracting layer2 SimAM 6 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.48it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.57s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.43it/s]\n",
            "Extracting layer2 relu 12 activations: 100%|██████████| 1588/1588 [01:15<00:00, 20.98it/s]\n",
            "Extracting layer2 relu 12 activations: 100%|██████████| 1123/1123 [00:53<00:00, 21.02it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 65.32it/s]\n",
            "Extracting layer2 relu 13 activations: 100%|██████████| 1588/1588 [01:15<00:00, 20.99it/s]\n",
            "Extracting layer2 relu 13 activations: 100%|██████████| 1123/1123 [00:53<00:00, 21.08it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.57s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 56.74it/s]\n",
            "Extracting layer2 SimAM 7 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.33it/s]\n",
            "Extracting layer2 SimAM 7 activations: 100%|██████████| 1123/1123 [00:53<00:00, 21.04it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.58s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.08it/s]\n",
            "Extracting layer2 relu 14 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.83it/s]\n",
            "Extracting layer2 relu 14 activations: 100%|██████████| 1123/1123 [00:53<00:00, 20.96it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.76it/s]\n",
            "Extracting layer2 relu 15 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.12it/s]\n",
            "Extracting layer2 relu 15 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.42it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.07it/s]\n",
            "Extracting layer2 SimAM 8 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.10it/s]\n",
            "Extracting layer2 SimAM 8 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.34it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.50s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.00it/s]\n",
            "Extracting layer2 relu 16 activations: 100%|██████████| 1588/1588 [01:15<00:00, 20.98it/s]\n",
            "Extracting layer2 relu 16 activations: 100%|██████████| 1123/1123 [00:53<00:00, 21.09it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 62.10it/s]\n",
            "Extracting layer2 relu 17 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.21it/s]\n",
            "Extracting layer2 relu 17 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.48it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 57.16it/s]\n",
            "Extracting layer2 SimAM 9 activations: 100%|██████████| 1588/1588 [01:13<00:00, 21.50it/s]\n",
            "Extracting layer2 SimAM 9 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.54it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 56.30it/s]\n",
            "Extracting layer2 relu 18 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.17it/s]\n",
            "Extracting layer2 relu 18 activations: 100%|██████████| 1123/1123 [00:53<00:00, 21.04it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.55s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 68.28it/s]\n",
            "Extracting layer2 relu 19 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.18it/s]\n",
            "Extracting layer2 relu 19 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.27it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.55s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 66.97it/s]\n",
            "Extracting layer2 SimAM 10 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.75it/s]\n",
            "Extracting layer2 SimAM 10 activations: 100%|██████████| 1123/1123 [00:54<00:00, 20.72it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:16<00:00,  1.60s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 63.75it/s]\n",
            "Extracting layer2 relu 20 activations: 100%|██████████| 1588/1588 [01:16<00:00, 20.84it/s]\n",
            "Extracting layer2 relu 20 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.25it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 68.54it/s]\n",
            "Extracting layer2 relu 21 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.02it/s]\n",
            "Extracting layer2 relu 21 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.28it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 68.65it/s]\n",
            "Extracting layer2 SimAM 11 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.25it/s]\n",
            "Extracting layer2 SimAM 11 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.49it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 62.64it/s]\n",
            "Extracting layer2 relu 22 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.33it/s]\n",
            "Extracting layer2 relu 22 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.31it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 61.61it/s]\n",
            "Extracting layer2 relu 23 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.10it/s]\n",
            "Extracting layer2 relu 23 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.35it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.59s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 56.02it/s]\n",
            "Extracting layer2 SimAM 12 activations: 100%|██████████| 1588/1588 [01:15<00:00, 21.13it/s]\n",
            "Extracting layer2 SimAM 12 activations: 100%|██████████| 1123/1123 [00:54<00:00, 20.62it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:16<00:00,  1.60s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 65.50it/s]\n",
            "Extracting layer2 relu 24 activations: 100%|██████████| 1588/1588 [01:17<00:00, 20.57it/s]\n",
            "Extracting layer2 relu 24 activations: 100%|██████████| 1123/1123 [00:53<00:00, 20.91it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 67.97it/s]\n",
            "Extracting layer2 relu 25 activations: 100%|██████████| 1588/1588 [01:15<00:00, 20.94it/s]\n",
            "Extracting layer2 relu 25 activations: 100%|██████████| 1123/1123 [00:52<00:00, 21.43it/s]\n",
            "Training Progress: 100%|██████████| 10/10 [00:15<00:00,  1.53s/it]\n",
            "Evaluation Progress: 100%|██████████| 71/71 [00:01<00:00, 68.98it/s]\n",
            "Extracting layer2 SimAM 13 activations: 100%|██████████| 1588/1588 [01:14<00:00, 21.20it/s]\n",
            "Extracting layer2 SimAM 13 activations:   2%|▏         | 24/1123 [00:00<00:44, 24.89it/s]"
          ]
        }
      ]
    }
  ]
}